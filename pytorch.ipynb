{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a1851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import re\n",
    "\n",
    "df = pd.read_csv(\"fake_news_dataset.csv\")\n",
    "texts = df[\"text\"].astype(str).tolist()\n",
    "labels, uniques = pd.factorize(df[\"label\"])   #The factorize function in pandas is used to make two kinds of lists one of which are number forms of the labels, i.e. 1 for Real and 0 for Fake\n",
    "num_classes = len(uniques)  #What are the unique labels in the uniques list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe17be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cleaning: 20000\n"
     ]
    }
   ],
   "source": [
    "def clean_text(s):\n",
    "    s = str(s).lower()                          \n",
    "    s = re.sub(r'http\\S+|www\\.\\S+', '', s)       \n",
    "    s = re.sub(r'<.*?>', '', s)                  \n",
    "    s = re.sub(r'[^a-z0-9\\s]', ' ', s)           \n",
    "    s = re.sub(r'\\s+', ' ', s).strip()           \n",
    "    return s\n",
    "\n",
    "df['text'] = df['text'].apply(clean_text)\n",
    "df['label'] = df['label'].astype(str).str.strip().str.lower()\n",
    "df = df.dropna(subset=['text', 'label'])\n",
    "\n",
    "print(\"Rows after cleaning:\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72293145",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function is used to tokenize the text\n",
    "def tokenizer(s): return s.lower().split()\n",
    "all_tokens = [tokenizer(t) for t in texts]\n",
    "vocab = {\"<PAD>\":0,\"<UNK>\":1}\n",
    "for tokens in all_tokens:\n",
    "    for w in tokens:\n",
    "        if w not in vocab: vocab[w] = len(vocab)        #This line assigns each word of the text a unique number that represents the word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "761b8f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 20\n",
    "def encode(tokens):\n",
    "    ids = [vocab.get(w,1) for w in tokens]  #Makes a list of unique numbers assigned to each token in the text\n",
    "    ids=ids[:MAX_LEN]       #Reduces the characters to the minimum number of characters required\n",
    "    return ids + [0]*(MAX_LEN - len(ids))   #In case the list of the unique numbers is too low, we add zeroes to fill up the remaining space\n",
    "\n",
    "X = torch.tensor([encode(t) for t in all_tokens], dtype=torch.long) \n",
    "y = torch.tensor(labels, dtype=torch.long)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ebed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class M(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, num_classes):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.fc = nn.Linear(emb_dim, num_classes)\n",
    "    def forward(self, x):\n",
    "        z = self.e(x).mean(dim=1)\n",
    "        return self.fc(z)\n",
    "\n",
    "model = M(len(vocab), emb_dim=32, num_classes=num_classes)\n",
    "opt = optim.Adam(model.parameters(), lr=0.01)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b7762",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "for ep in range(1, EPOCHS+1):\n",
    "    model.train()\n",
    "    logits = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96c9f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6fd10a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
